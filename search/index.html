<!DOCTYPE html>

<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<link rel="stylesheet" href="/css/screen.css">
	<link rel="apple-touch-icon" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
	<link rel="icon" type="image/png" href="/images/favicon.png">
	<link rel="stylesheet"
		href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">
	<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
	
	<script>
		window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) }; ga.l = +new Date;
		ga('create', '', 'auto');
		ga('send', 'pageview');
	</script>
	<script async src='https://www.google-analytics.com/analytics.js'></script>
	

	<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Search | CCAI - KDB</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Search" />
<meta name="author" content="vict0rsch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Climate Change AI project at Mila‚Äôs shared knowledge base" />
<meta property="og:description" content="Climate Change AI project at Mila‚Äôs shared knowledge base" />
<link rel="canonical" href="https://cc-ai.github.io/search/" />
<meta property="og:url" content="https://cc-ai.github.io/search/" />
<meta property="og:site_name" content="CCAI - KDB" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://cc-ai.github.io/siteicon.png"},"name":"vict0rsch"},"url":"https://cc-ai.github.io/search/","headline":"Search","description":"Climate Change AI project at Mila‚Äôs shared knowledge base","author":{"@type":"Person","name":"vict0rsch"},"@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

	<link type="application/atom+xml" rel="alternate" href="https://cc-ai.github.io/feed.xml" title="CCAI - KDB" />

	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
</head>

<body class="">
	<header>
		<div class="wrapper">
			<section class="top-bar">
				<div class="logo"><a href="/"></a></div>
				<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
<nav>
	<a class="editor-link btn" href="cloudcannon:collections/_data/navigation.yml" class="btn"
		style="padding: 5px;"><strong>&#9998;</strong> Edit navigation</a>
	
	

	
	<a href="/" class="">Home</a>
	
	

	
	<a href="/about/" class="">About</a>
	
	

	
	<a href="/faq/" class="">FAQ</a>
	
	

	
	<a href="https://github.com/cc-ai/kdb" class="">Github</a>
	
	<form action="/search/" method="get">
		<input type="search" name="q" 
			placeholder="" autofocus>
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
		<input type="submit" value="Search" style="display: none;">
	</form>
</nav>
			</section>
			<section class="hero_search">
				<h1>Visualizing the Consequences</h1>
				<h1> of Climate Change</h1>
				<p>The shared and open knowledge base.</p>
				<form action="/search/" method="get">
	<input type="search" name="q"  placeholder="Looking for something?" autofocus>
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form>
			</section>
		</div>

	</header>
	<section class="content">
		<div class="wrapper">
			<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
					
					
					"workflow-workflow-whoswho": {
						"id": "workflow-workflow-whoswho",
						"title": "Who's who?",
						"categories": "workflow",
						"url": " /workflow/workflow-whoswho/",
						"content": "Who‚Äôs who?\n\nLearn about others, share about yourself!\n\n(every field is obviously optional)\n\n\n  \n    \n      Github\n      Name\n      Twitter / website\n      Contribution\n      Affiliation\n      Time dedication\n      Currently working on\n      Interests / Other\n    \n  \n  \n    \n      @vict0rsch\n      Victor Schmidt\n      vict0rsch, vict0rs.ch\n      ml, meta, data\n      PhD @ Mila\n      50-75%\n      Attention Cycle GANs\n      previously Public Interest Entrepreneur in France ; built metada.org\n    \n    \n      @sashavor\n      Sasha Luccioni\n      Mila profile\n      ml, meta, data, behavioral\n      Postdoc @ Mila\n      150%\n      Segmentation\n      ¬†\n    \n    \n      @elenab\n      Elena Busila\n      LinkedIn\n      frontend, backend, devops, tooling\n      AI Developer @Element AI\n      20% of my work week when possible\n      Frontend\n      ¬†\n    \n  \n\n\n(Discuss this document in #39)"
					}
					
				
			
		
			
				
					,
					
					"workflow-workflow-gettingstarted": {
						"id": "workflow-workflow-gettingstarted",
						"title": "Github at `cc-ai` : getting started ü•ã",
						"categories": "workflow",
						"url": " /workflow/workflow-gettingstarted/",
						"content": "Github at cc-ai : getting started ü•ã\n\nHello and welcome to the CCAI GitHub!\n\nIn this repository, we will of course share code, but also links, articles, websites, and ideas. We will also use it for defining who does what task (i.e. ticket) and follow the progress of tickets and tasks as they evolve.\n\nDon‚Äôt worry if you‚Äôve never used GitHub before! You can actually use GitHub without knowing ANY code at all. It‚Äôs really a straightforward tool, and this document will help you cover the basics.\n\nGit üåµ\n\nGit is a software to do version control, which means it will save any changes being done without overwriting any past work. This means that even if several people are working on the same file at the same time, each person can upload their changes to the page, and Git will save both copies. Later, they can be  merged  together without anyone losing their work. You can even go back to a previous version at any point, because Git will keep a history of every change ever made. Typically, git is used via a terminal or command line and stores the versions on your computer. But GitHub allows us to store the content and versions online ; plus, it adds a user interface on top of Git, which makes it possible to download and change files from your browser or your desktop, make comments, suggest fixes, etc.\n\nVocabulary üôä\n\nSome useful GitHub vocabulary (from this guide)\n\nMarkdown: A way to write text files so that they are rendered beautifully on Github without the hastle of using html. For instance, if you start a line with # This is a title, it will be rendered by Github as a Top-level title (as # Github at cc-ai : getting started ü•ã). If you add a # it will be displayed as a secondary title (as ## Vocabulary üôä ) and so on until ###### minor title. Including links is extremely easy too! [website](https://website.com) will be rendered like this: website. These special text files have a .md extension. On GitHub if there is a Readme.md file in the current folder you‚Äôre looking into, it will be automatically rendered. If you click on a specific .md file, it will also be rendered. To see the raw text, before rendering, you can just click on the raw button (no shit‚Ä¶). Remember: Markdown is easy, ask for help if you‚Äôre stuck with something. In the mean time, checkout this cheatsheet to learn in 2 minutes how to use Markdown\n\n\n\nRepository or Repo : A directory or storage space where your projects can live. It can be local to a folder on your computer, or it can be a storage space on GitHub or another online host. You can keep code files, text files, image files, you name it, inside a repository.\n\nCommit: This is the command that gives Git its power. When you commit, you are taking a ‚Äúsnapshot‚Äù of your repository at that point in time, giving you a checkpoint to which you can reevaluate or restore your project to any previous state.\n\nBranch: How do multiple people work on a project at the same time without Git getting them confused? Usually, they ‚Äúbranch off‚Äù of the main project with their own versions full of changes they themselves have made. After they‚Äôre done, it‚Äôs time to ‚Äúmerge‚Äù that branch back with the ‚Äúmaster,‚Äù the main directory of the project.\n\nIssue: Although the name may sound negative  (‚ÄúOh no, there‚Äôs an issue with my project!‚Äù) , ‚Äòissue‚Äô is just the name used by GitHub for different tasks that contributors can assign to themselves. You can open an issue when you‚Äôve defined it as something that needs to be worked on, tag it with labels depending on what it involves, and then assign it to yourself (or someone else!). A very important document that explains this workflow for the cc-ai project process can be found here.\n\nWhat we will use GitHub for üî¶\n\n\n  \n    Sharing code : for the coders among us, GitHub will be a way to test out different parameters, make changes to the code, clone (a.k.a.) copy other repositories that we can test, share results, etc. This will be done via the various repositories in the project, which can be seen at https://github.com/cc-ai\n  \n  \n    Tracking progress: Even if the task that you are working on doesn‚Äôt involve coding (e.g. literature review, experimental testing, etc.), it‚Äôs useful for the rest of the team to know that you are working on a certain task (or issue), and what the progress on it is: whether it is open, closed, in progress, pending, etc. We will do this via the Kanban: https://github.com/cc-ai/kdb/projects/4\n  \n  \n    Sharing resources: A section of the repository is dedicated specifically to sharing common resources : https://github.com/cc-ai/kdb/tree/master/resources. These can be research papres, code, news articles, tools, etc. If you encounter something useful in your literature review (or even during your spare time!), add it to the resource section!\n  \n  \n    Sharing ideas:  If you see an open ticket that is labelled as ‚Äúhelp wanted‚Äù, or if you simply have an idea about a task that someone else is working on, don‚Äôt hesitate to leave a comment on the issue: it can help open a discussion and generate new ideas!\n  \n  \n    Collaborating with external contributors: We are lucky enough to have a group of people interested in CCAI, who want to help us with different tasks depending on their domain of expertise: UI design, front-end development, economics.. the sky is the limit! To make this collaboration as smooth as possible, we want to give them specific tasks and ways to help us, check in with progress, ask questions, etc. GitHub is the place to do this!\n  \n\n\nSome Brief Tutorials\n\nAdding a paper from a link\n\n\n  From the home page (https://github.com/cc-ai/kdb) click on resources in the top folder structure, then on papers (or the link provided): you should be at https://github.com/cc-ai/kdb/tree/master/resources/papers\n  Remember, by default, Github displays the file called Readme.md\n  You can edit this file and add your preferred paper by clicking on the pencil icon to the top right of the displayed Readme\n  Add a line with your paper line this * [paper title](https:// link to paper)\n\n\n\n\nAdding a paper from a pdf\n\nIf you can simply add a link to this pdf, it‚Äôs better as it makes the hole repository heavier for others to sync with. But if you can‚Äôt and want to share the file, here‚Äôs how to:\n\n\n  Host it elsewhere (Google Drive or something)\n  Host it on the repository\n    \n      From the home page (https://github.com/cc-ai/kdb) click on resources in the top folder structure, then on papers (or the link provided): you should be at https://github.com/cc-ai/kdb/tree/master/resources/papers\n      Click on Upload files\n      Drag and drop or choose your files\n      Commit (= save)\n      Copy link to file\n    \n  \n  Add the hosted file link to the Readme.md as described previously\n\n\n\n\nOpening an issue\n\nWhy\n\nRemember, issues are used to track problems, open discussions about a topic or simply create a task to be done. Basic use cases include:\n\n\n  Getting people‚Äôs opinion on a matter (like victo did for the who‚Äôs who -&gt; see #39)\n  Signaling a bug in some code (unexpected behavior, error in execution, installation issues and so on)\n  Reminding yourself (and possibly others) about something to be done (like the example issue below -&gt; see #43 )\n\n\nHow\n\n\n  From the home page (https://github.com/cc-ai/kdb) click on issues in the top folder structure: this should bring you to https://github.com/cc-ai/kdb/issues\n  This will show you the list of currently open issues\n  You can filter the issues by Author, Labels, Assignee, or sort by date\n  To open a new issue, click on New Issue, in green at the top right of the list of open issues\n  When opening an issue, you should add: a title and a brief (one or two sentence) summary\n  Don‚Äôt forget to label it with the corresponding label from the Labels dropdown list on the right (for more information about labels, read this: https://github.com/cc-ai/kdb/tree/master/workflow)\n  If you already know who will be working on the issue, add an Assignee from the list on the right. If not, you can leave it blank.\n\n\n\n\nAssigning an issue to yourself\n\n\n  When you have found an issue that you want to tackle, possibly opened by someone else, click on its name\n  To assign it to yourself, click Assignees on the right of the screen and select your GitHub handle from the list\n  If you want to add details or comments, use the Write section at the bottom of the page\n\n\nClosing an issue\n\n\n  When the issue is solved, use the close and comment button\n  You can always re-open an issue later if the fix is not complete or the same problem arises in a new context or whatever\n  For instance, the example issue above, #43, is now closed because gifs have been added\n\n\nBravo! You‚Äôre all set! üí™ Now checkout the workflow‚Äôs guide on using cc-ai‚Äôs labels on issues\n\nGetting Started ‚ö°Ô∏è\n\nIf you want to just dive in and get your hands dirty - go for it! Look at the tickets in the Kanban, choose the one that fits what you will start working on (check with Sasha or Karthik if you don‚Äôt know what to pick), and get started!\n\nIf you want more information about GitHub (or Git), or to learn how to use it via command line, you can check out the resources below:\n\nGitHub for beginners Part 1\n\nGitHub for beginners Part 2\n\nHow to Use GitHub\n\nIf you have any questions about GitHub, don‚Äôt hesitate to reach out to Sasha Luccioni (@sashavor) or Victor Schmidt (@vict0rsch) or simply open an issue, we‚Äôll help you ! üë©‚Äç‚úàÔ∏è üë®‚Äç‚úàÔ∏è"
					}
					
				
			
		
			
				
					,
					
					"workflow-workflow-example": {
						"id": "workflow-workflow-example",
						"title": "An example file to play around with markdown",
						"categories": "workflow",
						"url": " /workflow/workflow-example/",
						"content": "An example file to play around with markdown\n\n9gag"
					}
					
				
			
		
			
				
					,
					
					"workflow-workflow-readme": {
						"id": "workflow-workflow-readme",
						"title": "Workflow üåä",
						"categories": "workflow",
						"url": " /workflow/workflow-Readme/",
						"content": "Workflow üåä\n\nHow we use Github üöâ\n\n(New to Github ? -&gt; How to get started w/ Github, cc-ai style)\n\nCode repositories depend on the cc-ai organization, managed by @vict0rsch and @sashavor.\n\nThere are 2 teams (mainly):\n\n\n  The Core Team is composed of people at Mila working at least 50% of their time on this project\n  The Contributors Team is composed of people affiliated to other organizations and/or volunteering to spend some time on this project\n\n\nThe organization currently has these repositories:\n\n\n  kdb -&gt; this is the main shared repo, the CC-AI Knowledge Base\n  floods-frontend (self-explanatory)\n  floods-backend (self-explanatory)\n  floods-gans -&gt; where we experiment with generative models to simulate floods\n\n\nIf you‚Äôd rather have your own cc-ai repository for the task you work on, feel free to open a  issue\n\nGood practices üëç\n\nGit üåµ\n\nRead through these commit guidelines (~10 min) as they will help us work together better. A little more advanced content can be found here - it walks you though the differences between merging and rebasing branches\n\nAlso if you like Github from the command line, checkout Github‚Äôs own tool: hub\n\nThe CCAI Status Project üîî\n\nIf you click on Projects, to the right of Issues, you‚Äôll find the CCAI Status project. This Kanban-style project helps us track issues and tasks.\n\nWhen you create an issue add it to the CCAI Status project (to the right of the issue editting interface, below Assignees and Labels) iff it is a concrete üî¨ issue (bug, to do etc.). Please keep open discussions (as #16 or #37, i.e. issues with the  label) out of there.\n\nYou can always add an issue using the + Add card button to the top right of the project‚Äôs page.\n\nDo update the status of issues you are assigned‚ùó\n\nIssues and Labels üí•\n\nSome guidelines to understand our issues and labels\n\n\n  \n    Use kdb‚Äôs issues for general purpose issues the community should be aware or any kind of question you have\n\n    \n      If you work on a specific repository (floods-gans for instance) use its issues for everyday tasks, but kdb‚Äôs for general concerns\n    \n  \n  Assign people to issues (maybe yourself)\n  \n    Use Labels!\n\n    \n      Use the  label to acknowledge the issue and state you‚Äôve started working on it\n      Use the priority tags ( or )\n      Label as  issues relating to the overall CC-AI project and its management\n      Use the  label to signal thoughts you‚Äôve had which may someday be relevant\n      Even if you‚Äôre not assigned to an issue, if it bears the  tag you probably can still do something\n      If you‚Äôre in some kind of trouble and need people‚Äôs advice, use the \n      To open a discussion about anything, get people‚Äôs opinions, use the \n      The  label should never be used. Except for extraordinary issues.\n      Use domain: labels for people to be able to quickly pick up what‚Äôs relevant to them. See domains\n    \n  \n  Close issues when resolved. They may be re-openned later on. You may also lock a conversation if the decision is final.\n  Suggest improvements to these guidelines and practices\n\n\nReusing kdb‚Äôs labels in other repositories üè∑\n\nThis procedure describes how to import kdb‚Äôs labels into your repositories / other cc-ai repositories.\n\nThis will overwrite your labels so if you want your own labels you can do this once and then delete settings.yml otherwise it will delete your repo-specific labels when pushed later on.\n\nAdd a .github folder and a .github/settings.yml at the repo‚Äôs root.\n\nIf labels.yml is up to date, copy its content into your .github/settings.yml.\n\nOtherwise run this script in your browser console on page https://github.com/cc-ai/kdb/labels and add the created file to .github/.\n\nIt works like this:\n\n\n  Get labels as a list of objects with fields name color and description\n  Create a yml-compatible string out\n  Download out as a settings.yml file\n\n\nSlack üì°\n\nFollow the #git-kdb channel to monitor this repo‚Äôs activity. If you‚Äôre not in our workspace, see contact"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-websites-readme": {
						"id": "resources-resources-websites-readme",
						"title": "Websites üñ•",
						"categories": "resources",
						"url": " /resources/resources-websites-Readme/",
						"content": "Websites üñ•\n\nEnvironmental inspiration\n\n\n  Hazegazer : Real-time analysis and visualization tool for enhanced crisis management\n  Uttarakhand Tourism : With a combination of climate data, hazard data, socioeconomic data, tourism data and climate projections, this dashboard provides insights into trends, current and future vulnerabilities of this sensitive sector.\n  Project X : Project X is a WWF founded corporate accelerator which helps organisations adopt sustainable innovations in their supply chains. Our focus is to help entire industries step change their sustainability performance, together.\n  Les hivers enneig√©s de votre enfance ne reviendront jamais (Radio Canada)\n\n\nUX inspiration\n\n\n  Nuclear Dissent\n  360 Syria (Amnesty International)"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-tools-readme": {
						"id": "resources-resources-tools-readme",
						"title": "Tools  üõ†",
						"categories": "resources",
						"url": " /resources/resources-tools-Readme/",
						"content": "Tools  üõ†\n\nImages\n\n\n  https://add0n.com/save-images.html (download all images in your browser‚Äôs current page)\n  https://github.com/fidler-lab/curve-gcn (Fast Interactive Object Annotation with Curve-GCN - CVPR 2019)\n\n\nDev\n\n\n  sshcode Run VS Code on any server over SSH.\n  PySnooper Never use print for debugging again\n  tqdm A fast, extensible progress bar for Python and CLI"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-papers-readme": {
						"id": "resources-resources-papers-readme",
						"title": "Papers üìú",
						"categories": "resources",
						"url": " /resources/resources-papers-Readme/",
						"content": "Papers üìú\n\nThese are the most relevant papers, do add the ones you like too!\n\nWe‚Äôre also building a more exhaustive list on Zotero. Join our team and share your papers there too :)\n\nML\n\n\n  Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\n  Unsupervised Attention-guided Image-to-Image Translation\n  Semantic Image Synthesis with Spatially-Adaptive Normalization\n  A Closed-form Solution to Photorealistic Image Stylization\n  Image-to-image translation for cross-domain disentanglement\n  InstaGAN: Instance-aware image-to-image translation\n  Semantic Image Synthesis with Spatially-Adaptive Normalization"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-outreach-readme": {
						"id": "resources-resources-outreach-readme",
						"title": "Outreach üì£",
						"categories": "resources",
						"url": " /resources/resources-outreach-Readme/",
						"content": "Outreach üì£\n\nA folder to store outreach documents and presentations.\n\n\n  Executive Summary (Yoshua Bengio and Jennifer Chayes) (01/19) (Google Doc)\n  Slide deck (Victor Schmidt) (early 02/19) (Slides.io)"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-news-readme": {
						"id": "resources-resources-news-readme",
						"title": "News üóû",
						"categories": "resources",
						"url": " /resources/resources-news-Readme/",
						"content": "News üóû\n\n\n  Andrew Ng hosts symposium on AI and climate change, invites students to bootcamp\n  The Weather Channel flooded Charleston to make you give a damn"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-data-readme": {
						"id": "resources-resources-data-readme",
						"title": "Data üíæ",
						"categories": "resources",
						"url": " /resources/resources-data-Readme/",
						"content": "Data üíæ"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-code-readme": {
						"id": "resources-resources-code-readme",
						"title": "Code üíª",
						"categories": "resources",
						"url": " /resources/resources-code-Readme/",
						"content": "Code üíª\n\nGoogle APIs\n\n\n  Creating point clouds with Google Street View (depth)\n    \n      https://stackoverflow.com/questions/52790436/convert-depth-map-base64-of-google-street-view-to-image\n      https://github.com/proog128/GSVPanoDepth.js\n      https://stackoverflow.com/questions/48219613/height-elevation-of-a-pixel-from-ground-in-google-street-view\n      https://github.com/wearenocomputer/ofxGSVDepthmap\n    \n  \n\n\nGANs\n\n\n  Pytorch GAN Zoo (FAIR)\n  CycleGAN and pix2pix in PyTorch\n  Unsupervised Attention-guided Image-to-Image Translation\n  Semantic Image Synthesis with SPADE\n\n\nML\n\n\n  Awesome Data Science with Python projects for every kind of data analysis / processing / modeling / inference etc.\n\n\nClimate Science"
					}
					
				
			
		
			
				
					,
					
					"resources-resources-readme": {
						"id": "resources-resources-readme",
						"title": "Shared Resources ‚òÄÔ∏è",
						"categories": "resources",
						"url": " /resources/resources-Readme/",
						"content": "Shared Resources ‚òÄÔ∏è\n\n\n  \n    \n      Link üîó\n      Description  üìã\n    \n  \n  \n    \n      code\n      Links to relevant resources about coding stuff: repos, libraries, tutorials etc.\n    \n    \n      data\n      Links to data sources\n    \n    \n      news\n      News articles relevant to either climate change (climate science, econ, behaviors etc.), or AI + CC\n    \n    \n      outreach\n      Outreach resources: papers written, presntation documents etc.\n    \n    \n      papers\n      Important papers for the community to be aware of\n    \n    \n      tools\n      Curated list of useful tools\n    \n    \n      websites\n      Interesting websites, be it for their content, presentation (UI/UX) or intent"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-ux-readme": {
						"id": "domains-domains-ux-readme",
						"title": "User Research üìá",
						"categories": "domains",
						"url": " /domains/domains-ux-Readme/",
						"content": "User Research üìá\n\nWe need to identify our target users, their needs/expectations, and better define our value proposition. We need to understand how our users understand science and how much of it they expect. We want to find the sweet spot between scientific credibility and user-friendliness.\n\nAlongside the behavioral research, we need to test as soon as possible how people perceive and interpret our approach and goals. We also need to evaluate if the current hypothesis (image of one‚Äôs home) is going to make them change their mind or their behavior regarding climate change. With the help of a UI designer, we should put out wireframe (drawings of what the website could look like) to do the testing as soon as we have identified our users."
					}
					
				
			
		
			
				
					,
					
					"domains-domains-other-readme": {
						"id": "domains-domains-other-readme",
						"title": "Other Initiatives üéâ",
						"categories": "domains",
						"url": " /domains/domains-other-Readme/",
						"content": "Other Initiatives üéâ\n\nInformation Retrieval\nAt the last meeting at MSR, Devon proposed to use IR to retrieve images of climate change instead of generating them on the go. This can be pursued either as a standalone endeavour, or as complementary to the generative approach : i.e. when the viewer‚Äôs house is too different from the ones that our model is trained on, we can retrieve a photo of a similar house affected by extreme weather events. This would entail that the IR system would have to communicate with our backend.\n\nClimate Conversational Agent\n\nEven though a picture is worth a thousand words, it would be interesting to add other modalities to the tool, for instance for people who want more information about climate change on a global level or on a community level. For people who are interested on the project but who have a background in NLP, we can maybe create a climate conversational agent who can initially answer some basic questions about climate change, and eventually make it more complex, translating the climate model output into language, e.g. ‚ÄúAccording to the NOAA climate model, [your city] in 2100 will be highly impacted by tornadoes and flooding, with coast lines receding by an average of 5m. Since your house is further from the coast, you will be less impacted by the flooding itself, but the impact of strong winds ‚Ä¶‚Äù"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-ml-readme": {
						"id": "domains-domains-ml-readme",
						"title": "Machine Learning ü§ñ",
						"categories": "domains",
						"url": " /domains/domains-ml-Readme/",
						"content": "Machine Learning ü§ñ\n\nTasks\n\nTest different models\n\nHaving acquired the data (whether real or simulated), it is necessary to test different generative model approaches to establish which works best (e.g. StarGAN, vid2vid, cycleGAN with attention, etc.).\n\nModifying segmentation automatically\n\nCycleGANs are good at changing texture but it is more difficult to make them change the image in more drastic ways. Controlling the changes at the level of textured segments might be easier. Recent results (SPADE) show that it is possible to transform a segmentation map into a realistic image quite convincingly. Since it is possible that a single end-to-end approach relying solely on images is not sufficient, we should also explore approaches that use segmentation maps and images in order to carry out more drastic changes to the input image (e.g. replace some ground segments by water segments). The pipeline would thus be: house image ‚Üí segmentation map ‚Üí modified (flooded) segmentation map ‚Üí flooded house image. See ‚ÄòDepth maps‚Äô below for a way to modify the segmentation map to paint water in it.\n\nDepth maps\n\nAlong with the street-level images that we query from the Google or Bing API, we can obtain depth maps of the buildings in the image that will allow us to calculate which pixels of the image to flood or not. A simple geometrical calculation (assuming a relative camera position, which StreetView can give us) allows to compute which pixels would be hidden by the water plane (given an ‚Äòaltitude‚Äô where the flood reaches). This will probably be necessary to make the output images more realistic (but we would need to pair this with the image segmentation, for example). The corresponding pixels in the segmentation map would have their label changed to ‚Äòwater‚Äô. This is important to make sure we paint only the right pixels as ‚Äòwater‚Äô.\n\nSim2Real\n\nWe can use Sim2Real techniques in order to transform the simulated images to be more realistic. This would be necessary if our GANs were trained mostly on simulated data.\n\nNeural Style Transfer\n\nThese are alternatives to CycleGAN types of models, where an optimization is performed at run-time in order to transform an image according to some style image. Does not need paired data. This might be used to paint water texture in the right places.\n\nFine tuning DeepLab (or other segmentation models)\n\nThere are several segmentation models trained on the Cityscapes dataset, which includes many street-level scenes similar to the ones that we will use. We can therefore use these models out-of-the-box to segment our ‚Äòbefore‚Äô images. However, they are not robust enough to recognize flooded or damaged houses and streets, which means that some training or fine-tuning is needed to use an existing segmentation model on our ‚Äòafter‚Äô images, in order to be able to pursue a segmentation-modification approach.\n\nWhat we have\n\nWe are working on using CycleGAN and Attention-Guided CycleGANS to apply floods to a non-flooded houses.\n\nRemember: when you run a model, store the current commit hash so that results are reproducible!\n\nCycleGAN\n\nTo Do\n\nAG-CycleGans\n\nTo Do"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-econ-readme": {
						"id": "domains-domains-econ-readme",
						"title": "Economic Modeling",
						"categories": "domains",
						"url": " /domains/domains-econ-Readme/",
						"content": "Economic Modeling\n\nWhen we add the action knobs to our tool, we will need to estimate the impact that both individual actions (e,g. biking 10km to work) and collective actions (e.g. going carbon free) will have (e.g. on average CO2 concentrations). We also have to choose the actions that people can/will make depending on where they live. It was also discussed that we can factor in the price of groceries or fuel in 80 years, to show people the consequences that they can expect on their budget and spending habits.\n\nTo do:\n\n\n  Find or design economic models which can convert action knobs (e.g. carbon tax price, or renewable energy portfolio target proportion) into climate variables (like CO2 equivalent concentration)."
					}
					
				
			
		
			
				
					,
					
					"domains-domains-dev-readme": {
						"id": "domains-domains-dev-readme",
						"title": "Web development üîÆ",
						"categories": "domains",
						"url": " /domains/domains-dev-Readme/",
						"content": "Web development üîÆ\n\nFront-end\nThe front-end will be critical. It needs to be flawless if we want things to get viral and emotionally compelling. Work with UX/UI is expected. We therefore need a front-end developer who will design a first version of the website, which will only show the images, and then integrate the behavioral knobs, links to actions, etc.\n\nBack-end\n\nWe need to design a back-end that will query the climate and GAN models and transmit the generated image to the front-end. This process needs to be seamless, which is relatively straightforward for the static MVP version of the tool, but will become more complex when we make the model interactive (by adding action knobs). If there are many knobs it becomes difficult to pre-compute climate trajectories for all of them (it would be too expensive), so some approximations are needed (e.g., merging all the configurations into a single dimension relating to the average amount of temperature forcing over the chosen period, or heavily discretizing the knob choices). In addition, will the on-the-fly generation of images be done on our servers or on the viewer‚Äôs computer? There are conceptual decisions that must be made up front so that we don‚Äôt end up reprogramming the backend later.\n\nFrancois, one of our team members, can do most of the work for the MVP during the summer. However he has no production experience and guidance in this matter would be helpful. We have started using Flask -&gt; https://github.com/cc-ai/floods-backend"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-data-readme": {
						"id": "domains-domains-data-readme",
						"title": "Data üéÅ",
						"categories": "domains",
						"url": " /domains/domains-data-Readme/",
						"content": "Data üéÅ\n\nAcquisition\n\nIn order to train the GANs we need to create a diverse dataset of places (houses, buildings, countryside and city etc.) which is also open (free of copyrights), showing places before and after an extreme climate event.\n\nIdeally we‚Äôd have paired images, the same location before and after the event, but recent advances in unpaired image to image translation (CycleGANs and variations for instance) give us hope that an unpaired dataset would suffice or that a large set of unpaired images could be successfully combined with a small set of paired ones.\n\nAs an MVP we have started with floods. We have gone through most major copyright-free images websites and gathered ~500 images of variable quality and relevance, of which we consider ~160 to be of good quality for the training of GANs (link to data).\n\nNow we need to improve and augment this dataset. We need to either find new open data sources, or acquire (buy) images. Photographers/Media, Governments/Emergency Agencies and Insurance companies may be leveraged.\n\nLabeling/Segmentation\n\nRecent advances (SPADE, Unsupervised Attention-guided Image-to-Image Translation etc. ) demonstrate how GANs can leverage segmentation information in order to generate locally-relevant features. In order to be able to explore such approaches, we need to segment (label pixel-wise) our images.\n\nThis can be done either manually (if the guidelines are well defined) or automatically, using existing models (e.g. DeepLab).The issue with existing models is that they are not trained on damaged houses with flooded streets and floating cars, so some fine-tuning or even retraining is needed. This brings us back to manually labeling data.\n\nSimulation\n\nAs explained above, the image data that the project needs is scarce. On the other part, relaxing one of our constraints (images being real) could help us gather more data. Simulated data could help in a variety of approaches:\n\n\n  Adding paired data to an unpaired dataset could ‚Äúguide‚Äù the GAN into the right training region and allow it to become more robust\n  Splitting the transformation process between a simulation-trained ‚Äúflood-segmenter‚Äù and a SPADE-like ‚Äúpainter‚Äù could give us more freedom and modularity.\n  Could be used not just to produce training data it could be used to generate videos of your flooded house\n\n\nNeeded:\n\n\n  Appropriate software\n  3D or 2.5D models of a diversity of houses and neighborhood\n  Computer graphics expertise\n\n\nNotes:\n\n\n  Water is generally muddy in floods, probably easier to simulate ( no complicated reflections)\n  Simulated images could be post-processed by GANs (see Sim2Real below)"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-climate-readme": {
						"id": "domains-domains-climate-readme",
						"title": "Climate modeling üå™",
						"categories": "domains",
						"url": " /domains/domains-climate-Readme/",
						"content": "Climate modeling üå™"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-behavior-readme": {
						"id": "domains-domains-behavior-readme",
						"title": "Behavioral Sciences üß†",
						"categories": "domains",
						"url": " /domains/domains-behavior-Readme/",
						"content": "Behavioral Sciences üß†\n\nThe project is based on research that has found that when people are given accurate depictions of how actions today affect outcomes tomorrow, they often change their behavior. However, as opposed to retirement savings, climate change awareness is difficult to translate into concrete actions. We would like someone to help supervise a summer intern who will look into the behavioral experimentation using our images.\n\nChoice of expected emotional impact\n\nWe therefore need to define:\n\n  Quantifiable behavior that we can measure or quantify and that we can target via our tool\n  The emotions that are provoked by our images and whether these are constructive or destructive\n  The attitude or opinion of the viewer with regards to the reality of climate change and whether it changed after using our tool"
					}
					
				
			
		
			
				
					,
					
					"domains-domains-readme": {
						"id": "domains-domains-readme",
						"title": "CCAI Task distribution üèó",
						"categories": "domains",
						"url": " /domains/domains-Readme/",
						"content": "CCAI Task distribution üèó\n\nHere is how we see the project could be split indo domains. Obviously there are overlaps and you should not read this compartmentalised silos, rather as contributing guidelines for you to find where and how you want to be part of the effort\n\n\n  \n    \n      Domain üìí\n      Description     üìã\n      Domain-specific Issues     üí•\n    \n  \n  \n    \n      Data\n      Help us gather and improve our data sets\n      \n    \n    \n      Machine Learning\n      We need to explore architectures, train models, compare performance, advance SOTA\n      \n    \n    \n      Economic Modeling\n      How to chose the best actions to suggest to users so as to maximize their impact\n      \n    \n    \n      Climate Modeling\n      How to adapt / scale / fine tune climate models to our usecases\n      \n    \n    \n      User Research (UX)\n      Who are our users? How to best convince them to take action? How to present our work?\n      \n    \n    \n      Web Development\n      Front and Back ends\n      \n    \n    \n      Behavioral Sciences\n      What emotions do we want to trigger? How do we measure the overall system efficiency? This target is not diffenrentiable‚Ä¶\n      \n    \n    \n      Other Initiatives\n      Everyone‚Äôs welcome to add their ideas! Like a Clilmate Change Chatbot or IR-based systems\n      \n    \n    \n      Meta\n      Comments and suggestions about the project management / tools / repos / the kdb itself\n      \n    \n  \n\n\nUse the domain: tags to track issuses and find out where you can help\n\nUse the Status Project to track advancement of each domain."
					}
					
				
			
		
			
				
					,
					
					"readme": {
						"id": "readme",
						"title": "Readme",
						"categories": "",
						"url": " /README/",
						"content": "CC-AI Shared Knowledge Database\n\nüåé &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üåç&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üåè\n\nHow to use üìÉ\n\nThis repository is the CCAI project‚Äôs knowledge database. We use it to:\n\n\n  Store resources (code, tools, news articles and so on)\n  Distribute tasks according to specific domains\n  Manage the project (workflow)\n\n\nContributing ü§ù\n\nGoal ü•Ö\n\nWe cannot stress enough how collaborative and open this project should be. This means that you may (and should) bring to the discussion anything you believe can be improved, suggest modifications to the workflow and share resources.\n\nAt first, it may seem pointless to just store a link as a line in this repository. But in the long run it will help the community a lot as nothing will be lost and it will be easy to refer new-comers to existing knowledge.\n\nIssues üí•\n\nWe use this repository‚Äôs issues to discuss everything. Have a look at the workflow to better understand how we use them.\n\nKeep in mind that both domain-specific issues (like questions/discussions about a GAN model or about a website feature) and meta issues (about how we manage this project, broken links, typos etc.) are relevant.\n\nGetting started ‚ö°Ô∏è\n\nNew to Github? ü¶é\n\nWe have compiled a shor list of basic things for you to know in order to make the most out of Github without needing to become a software engineer first -&gt; Github at cc-ai\n\nExperienced contributor ü¶ñ\n\nThe workflow‚Äôs Readme contains everything you need to know. Go through it at least once to get a feeling of how we want to work before you do your usual magic. Again, if you find some useless friction, open a domain:meta issue to discuss it.\n\nAccording to your background and skills, you will find the list of everything we need help with in domains/ along with relevant issues\n\nIn any case\n\nAdd yourself to our Who‚Äôs Who? if you plan on contributing !\n\nAbout üí°\n\nIn case you stubbled upon this repository inadvertantly, here is our story.\n\nThe CCAI project is an interdisciplinary project aimed at creating images of accurate, vivid, and personalized outcomes of climate change. Our goal is to use cutting-edge machine learning techniques to produce images of how neighborhoods and houses will look like following the effects of global warming. By creating a more visceral understanding of the effects of climate change, we aim to strengthen public support for necessary actions and motivate people to make impactful decisions. As a prototype, we first focus on modeling flood consequences on homes.\n\nFor a more detailed motivation explanation, read through our 2 pages executive summary\n\nAlso, you might be interested in oour ICLR 2019 Ai For Social Good workshop paper (~link to be added~)\n\nContact ‚úâÔ∏è\n\nThis project is lead by Sasha Luccioni (@sashavor), Karthik Mukkavilli (@mukkavilli) and Victor Schmidt (@vict0rsch) from Mila (@Mila-iqai), overseen by Yoshua Bengio and Jennifer Chayes.\n\nYou can contact us via email: {luccionis | mukkavis | schmidtv}@mila.quebec\n\nWe have a Slack workspace, get in touch with us so we add you to it!"
					}
					
				
			
		
	};
</script>
<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>
		</div>
	</section>

	<footer>
	<div class="wrapper">
		<p class="edit-footer"><a class="editor-link btn" href="cloudcannon:collections/_data/footer.yml" class="btn"
				style="padding: 5px;"><strong>&#9998;</strong> Edit footer</a></p>
		<ul class="footer-links">
			
			<li><a target="_blank" 
					href="https://facebook.com/"
					class="Facebook-icon" >
					
					
		<svg class="facebook" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,4V7H17A1,1 0 0,0 16,8V10H19V13H16V20H13V13H11V10H13V7.5C13,5.56 14.57,4 16.5,4M20,2H4A2,2 0 0,0 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	

					
					</a></li>
			
			<li><a target="_blank" 
					href="https://twitter.com/"
					class="Twitter-icon" >
					
					
		<svg class="twitter" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.46,6C21.69,6.35 20.86,6.58 20,6.69C20.88,6.16 21.56,5.32 21.88,4.31C21.05,4.81 20.13,5.16 19.16,5.36C18.37,4.5 17.26,4 16,4C13.65,4 11.73,5.92 11.73,8.29C11.73,8.63 11.77,8.96 11.84,9.27C8.28,9.09 5.11,7.38 3,4.79C2.63,5.42 2.42,6.16 2.42,6.94C2.42,8.43 3.17,9.75 4.33,10.5C3.62,10.5 2.96,10.3 2.38,10C2.38,10 2.38,10 2.38,10.03C2.38,12.11 3.86,13.85 5.82,14.24C5.46,14.34 5.08,14.39 4.69,14.39C4.42,14.39 4.15,14.36 3.89,14.31C4.43,16 6,17.26 7.89,17.29C6.43,18.45 4.58,19.13 2.56,19.13C2.22,19.13 1.88,19.11 1.54,19.07C3.44,20.29 5.7,21 8.12,21C16,21 20.33,14.46 20.33,8.79C20.33,8.6 20.33,8.42 20.32,8.23C21.16,7.63 21.88,6.87 22.46,6Z" /></svg>
	

					
					</a></li>
			
			<li><a target="_blank" 
					href="https://youtube.com/"
					class="YouTube-icon" >
					
					
		<svg class="youtube" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M10,16.5V7.5L16,12M20,4.4C19.4,4.2 15.7,4 12,4C8.3,4 4.6,4.19 4,4.38C2.44,4.9 2,8.4 2,12C2,15.59 2.44,19.1 4,19.61C4.6,19.81 8.3,20 12,20C15.7,20 19.4,19.81 20,19.61C21.56,19.1 22,15.59 22,12C22,8.4 21.56,4.91 20,4.4Z" /></svg>
	

					
					</a></li>
			
			<li><a target="_blank" 
					href="https://github.com/cc-ai/kdb"
					class="Github-icon" >
					
					
	<svg class="github" fill="#000000"  viewBox="0 0 24 24" width="25" height="25" xmlns="http://www.w3.org/2000/svg"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
	

					
					</a></li>
			
			<li><a 
					href="/feed.xml"
					class="RSS-icon" >
					
					
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"/><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
		

					
					</a></li>
			
		</ul>
		<p class="copyright">This project is lead at <a href="https://mila.quebec" target="_blank"
				rel="noopener noreferrer">Mila</a>, Quebec's Institute for Artificial Intelligence</p>
	</div>
</footer>
	<script>
		$(function () {
			$('a[href*=\\#]').not(".no-smooth").on('click', function (event) {
				var el = $(this.hash);
				if (el.length > 0) {
					// event.preventDefault();
					$('html,body').animate({ scrollTop: $(this.hash).offset().top - 50 }, 500);
				}
			});

			$('svg').click(function () {
				$(this).parent('form').submit();
			});
		});

		document.getElementById("open-nav").addEventListener("click", function (event) {
			event.preventDefault();
			document.body.classList.toggle("nav-open");
		});
	</script>
</body>

</html>